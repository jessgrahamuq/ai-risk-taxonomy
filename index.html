<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Risk Domain Taxonomy</title>
    <link href="https://fonts.googleapis.com/css2?family=Figtree:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Figtree', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            margin: 0;
            padding: 8px;
            background-color: #f8f9fa;
            font-weight: 400;
            line-height: 1.3;
        }
        
        .taxonomy-container {
            max-width: 1600px;
            margin: 0 auto;
            background: white;
            border-radius: 8px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.08);
            overflow: hidden;
        }
        
        .taxonomy-header {
            background: linear-gradient(135deg, #a12536 0%, #851e2b 100%);
            color: white;
            padding: 15px 20px;
            text-align: center;
        }
        
        .taxonomy-header h1 {
            margin: 0;
            font-size: 20px;
            font-weight: 700;
            letter-spacing: -0.5px;
        }
        
        .table-container {
            padding: 8px;
            background: white;
            overflow-x: auto;
        }
        
        /* Two-Column Layout */
        .columns-wrapper {
            display: table;
            width: 100%;
            min-width: 1200px;
            border-spacing: 8px;
        }
        
        .column {
            display: table-cell;
            width: 50%;
            vertical-align: top;
        }
        
        /* Individual Table Styling */
        .taxonomy-table {
            width: 100%;
            border-collapse: collapse;
            font-size: 12px;
            background: white;
            border-radius: 6px;
            overflow: hidden;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
        }
        
        .taxonomy-table td, .taxonomy-table th {
            border: 1px solid #ddd;
            padding: 8px 10px;
            vertical-align: top;
            text-align: left;
        }
        
        /* Domain header rows */
        .domain-header-row {
            background: var(--domain-color);
            color: var(--text-color);
            font-weight: 700;
            font-size: 13px;
        }
        
        .domain-header-row td {
            border-color: rgba(255,255,255,0.3);
            padding: 10px;
        }
        
        /* Domain-specific colors */
        .domain-1 { --domain-color: #1f78b4; --text-color: white; }
        .domain-2 { --domain-color: #b2df8a; --text-color: #333; }
        .domain-3 { --domain-color: #33a02c; --text-color: white; }
        .domain-4 { --domain-color: #fb9a99; --text-color: #333; }
        .domain-5 { --domain-color: #e31a1c; --text-color: white; }
        .domain-6 { --domain-color: #fdbf6f; --text-color: #333; }
        .domain-7 { --domain-color: #cab2d6; --text-color: #333; }
        
        .subdomain-header {
            font-weight: 600;
            color: #2c3e50;
            width: 180px;
        }
        
        .subdomain-description {
            color: #5a6c7d;
            line-height: 1.4;
        }
        
        /* Hover effects */
        .taxonomy-table tr:hover:not(.domain-header-row) {
            background-color: #f8f9fa;
        }
        
        /* Mobile Layout - Stack vertically */
        @media (max-width: 1100px) {
            .columns-wrapper {
                display: block;
                min-width: auto;
            }
            
            .column {
                display: block;
                width: 100%;
                margin-bottom: 12px;
            }
            
            .taxonomy-table {
                font-size: 11px;
            }
            
            .subdomain-header {
                width: 140px;
            }
            
            .taxonomy-table td, .taxonomy-table th {
                padding: 6px 8px;
            }
        }
        
        @media (max-width: 600px) {
            .taxonomy-table {
                font-size: 10px;
            }
            
            .subdomain-header {
                width: 120px;
            }
            
            .taxonomy-table td, .taxonomy-table th {
                padding: 4px 6px;
            }
        }
    </style>
</head>
<body>
    <div class="taxonomy-container">
        <div class="taxonomy-header">
            <h1>The AI Risk Domain Taxonomy</h1>
        </div>
        
        <div class="table-container">
            <div class="columns-wrapper">
                <!-- Left Column: Domains 1-5 -->
                <div class="column">
                    <table class="taxonomy-table">
                        <!-- Domain 1: Discrimination & toxicity -->
                        <tr class="domain-header-row domain-1">
                            <td colspan="2"><strong>1. Discrimination & toxicity</strong></td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">1.1 Unfair discrimination and misrepresentation</td>
                            <td class="subdomain-description">Unequal treatment of individuals or groups by AI, often based on race, gender, or other sensitive characteristics, resulting in unfair outcomes and unfair representation of those groups.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">1.2 Exposure to toxic content</td>
                            <td class="subdomain-description">AI that exposes users to harmful, abusive, unsafe or inappropriate content. May involve providing advice or encouraging action. Examples of toxic content include hate speech, violence, extremism, illegal acts, or child sexual abuse material, as well as content that violates community norms such as profanity, inflammatory political speech, or pornography.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">1.3 Unequal performance across groups</td>
                            <td class="subdomain-description">Accuracy and effectiveness of AI decisions and actions is dependent on group membership, where decisions in AI system design and biased training data lead to unequal outcomes, reduced benefits, increased effort, and alienation of users.</td>
                        </tr>
                        
                        <!-- Domain 2: Privacy & security -->
                        <tr class="domain-header-row domain-2">
                            <td colspan="2"><strong>2. Privacy & security</strong></td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">2.1 Compromise of privacy by obtaining, leaking, or correctly inferring sensitive information</td>
                            <td class="subdomain-description">AI systems that memorize and leak sensitive personal data or infer private information about individuals without their consent. Unexpected or unauthorized sharing of data and information can compromise user expectation of privacy, assist identity theft, or cause loss of confidential intellectual property.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">2.2 AI system security vulnerabilities and attacks</td>
                            <td class="subdomain-description">Vulnerabilities that can be exploited in AI systems, software development toolchains, and hardware, resulting in unauthorized access, data and privacy breaches, or system manipulation causing unsafe outputs or behavior.</td>
                        </tr>
                        
                        <!-- Domain 3: Misinformation -->
                        <tr class="domain-header-row domain-3">
                            <td colspan="2"><strong>3. Misinformation</strong></td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">3.1 False or misleading information</td>
                            <td class="subdomain-description">AI systems that inadvertently generate or spread incorrect or deceptive information, which can lead to inaccurate beliefs in users and undermine their autonomy. Humans that make decisions based on false beliefs can experience physical, emotional, or material harms</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">3.2 Pollution of information ecosystem and loss of consensus reality</td>
                            <td class="subdomain-description">Highly personalized AI-generated misinformation that creates "filter bubbles" where individuals only see what matches their existing beliefs, undermining shared reality and weakening social cohesion and political processes.</td>
                        </tr>
                        
                        <!-- Domain 4: Malicious actors & misuse -->
                        <tr class="domain-header-row domain-4">
                            <td colspan="2"><strong>4. Malicious actors & misuse</strong></td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">4.1 Disinformation, surveillance, and influence at scale</td>
                            <td class="subdomain-description">Using AI systems to conduct large-scale disinformation campaigns, malicious surveillance, or targeted and sophisticated automated censorship and propaganda, with the aim of manipulating political processes, public opinion, and behavior.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">4.2 Cyberattacks, weapon development or use, and mass harm</td>
                            <td class="subdomain-description">Using AI systems to develop cyber weapons (e.g., by coding cheaper, more effective malware), develop new or enhance existing weapons (e.g., Lethal Autonomous Weapons or chemical, biological, radiological, nuclear, and high-yield explosives), or use weapons to cause mass harm.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">4.3 Fraud, scams, and targeted manipulation</td>
                            <td class="subdomain-description">Using AI systems to gain a personal advantage over others such as through cheating, fraud, scams, blackmail, or targeted manipulation of beliefs or behavior. Examples include AI-facilitated plagiarism for research or education, impersonating a trusted or fake individual for illegitimate financial benefit, or creating humiliating or sexual imagery.</td>
                        </tr>
                        
                        <!-- Domain 5: Human-computer interaction -->
                        <tr class="domain-header-row domain-5">
                            <td colspan="2"><strong>5. Human-computer interaction</strong></td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">5.1 Overreliance and unsafe use</td>
                            <td class="subdomain-description">Anthropomorphizing, trusting, or relying on AI systems by users, leading to emotional or material dependence and to inappropriate relationships with or expectations of AI systems. Trust can be exploited by malicious actors (e.g., to harvest information or enable manipulation), or result in harm from inappropriate use of AI in critical situations (such as a medical emergency). Over reliance on AI systems can compromise autonomy and weaken social ties.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">5.2 Loss of human agency and autonomy</td>
                            <td class="subdomain-description">Delegating by humans of key decisions to AI systems, or AI systems that make decisions that diminish human control and autonomy, potentially leading to humans feeling disempowered, losing the ability to shape a fulfilling life trajectory, or becoming cognitively enfeebled.</td>
                        </tr>
                    </table>
                </div>
                
                <!-- Right Column: Domains 6-7 -->
                <div class="column">
                    <table class="taxonomy-table">
                        <!-- Domain 6: Socioeconomic & environmental harms -->
                        <tr class="domain-header-row domain-6">
                            <td colspan="2"><strong>6. Socioeconomic & environmental harms</strong></td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">6.1 Power centralization and unfair distribution of benefits</td>
                            <td class="subdomain-description">AI-driven concentration of power and resources within certain entities or groups, especially those with access to or ownership of powerful AI systems, leading to inequitable distribution of benefits and increased societal inequality.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">6.2 Increased inequality and decline in employment quality</td>
                            <td class="subdomain-description">Social and economic inequalities caused by widespread use of AI, such as by automating jobs, reducing the quality of employment, or producing exploitative dependencies between workers and their employers.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">6.3 Economic and cultural devaluation of human effort</td>
                            <td class="subdomain-description">AI systems capable of creating economic or cultural value, including through reproduction of human innovation or creativity (e.g., art, music, writing, coding, invention), destabilizing economic and social systems that rely on human effort. The ubiquity of AI-generated content may lead to reduced appreciation for human skills, disruption of creative and knowledge-based industries, and homogenization of cultural experiences.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">6.4 Competitive dynamics</td>
                            <td class="subdomain-description">Competition by AI developers or state-like actors in an AI "race" by rapidly developing, deploying, and applying AI systems to maximize strategic or economic advantage, increasing the risk they release unsafe and error-prone systems.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">6.5 Governance failure</td>
                            <td class="subdomain-description">Inadequate regulatory frameworks and oversight mechanisms that fail to keep pace with AI development, leading to ineffective governance and the inability to manage AI risks appropriately.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">6.6 Environmental harm</td>
                            <td class="subdomain-description">The development and operation of AI systems that cause environmental harm, such as through energy consumption of data centers or the materials and carbon footprints associated with AI hardware.</td>
                        </tr>
                        
                        <!-- Domain 7: AI system safety, failures & limitations -->
                        <tr class="domain-header-row domain-7">
                            <td colspan="2"><strong>7. AI system safety, failures & limitations</strong></td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">7.1 AI pursuing its own goals in conflict with human goals or values</td>
                            <td class="subdomain-description">AI systems that act in conflict with ethical standards or human goals or values, especially the goals of designers or users. These misaligned behaviors may be introduced by humans during design and development, such as through reward hacking and goal misgeneralisation, and may result in AI using dangerous capabilities such as manipulation, deception, or situational awareness to seek power, self-proliferate, or achieve other goals.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">7.2 AI possessing dangerous capabilities</td>
                            <td class="subdomain-description">AI systems that develop, access, or are provided with capabilities that increase their potential to cause mass harm through deception, weapons development and acquisition, persuasion and manipulation, political strategy, cyber-offense, AI development, situational awareness, and self-proliferation. These capabilities may cause mass harm due to malicious human actors, misaligned AI systems, or failure in the AI system.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">7.3 Lack of capability or robustness</td>
                            <td class="subdomain-description">AI systems that fail to perform reliably or effectively under varying conditions, exposing them to errors and failures that can have significant consequences, especially in critical applications or areas that require moral reasoning.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">7.4 Lack of transparency or interpretability</td>
                            <td class="subdomain-description">Challenges in understanding or explaining the decision-making processes of AI systems, which can lead to mistrust, difficulty in enforcing compliance standards or holding relevant actors accountable for harms, and the inability in identify and correct errors.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">7.5 AI welfare and rights</td>
                            <td class="subdomain-description">Ethical considerations regarding the treatment of potentially sentient AI entities, including discussions around their potential rights and welfare, particularly as AI systems become more advanced and autonomous.</td>
                        </tr>
                        <tr>
                            <td class="subdomain-header">7.6 Multi-agent risks</td>
                            <td class="subdomain-description">Risks from multi-agent interactions due to incentives (which can lead to conflict or collusion) and/or the structure of multi-agent systems, which can create cascading failures, selection pressures, new security vulnerabilities, and a lack of shared information and trust.</td>
                        </tr>
                    </table>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
